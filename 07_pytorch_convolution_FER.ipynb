{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b9880fe",
   "metadata": {},
   "source": [
    "# pyTorch Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4453fb",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; border: 5px solid #a10000ff;\">\n",
    "\n",
    "**Hinweis:** In den Codezellen sind jeweils einige Codeteile nicht programmiert. Diesen Code müssen Sie ergänzen. Die jeweiligen Stellen sind mit einem Kommentar und dem Keyword **TODO** vermerkt und z.T. Stellen mit ... markiert.\n",
    "\n",
    "Ausserdem gibt es einige assert Statements. Diese geben einen Fehler aus, sollte etwas bei Ihrer Programmierung nicht korrekt sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa9d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import random\n",
    "import PIL.Image as Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e518e06",
   "metadata": {},
   "source": [
    "### Torch vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ca290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir prüfen ob eine Hardwarebeschleunigung möglich ist und verwenden diese, wenn sie verfügbar ist\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "torch.manual_seed(42) # Setze den Zufallsseed für Reproduzierbarkeit\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe145ed",
   "metadata": {},
   "source": [
    "## Weitere CNNs erstellen\n",
    "\n",
    "In diesem Notebook werden wir weitere CNNs erstellen. Dabei werden diese CNNs auf eine komplexere Problemstellung angewendet, nämlich auf die Klassifikation von Bildern von Gesichtern in erkannte Emotionen. Das Dataset, welches wir verwenden werden, ist das FER2013 Dataset, welche 48x48 Pixel grosse Bilder enthält und 7 Klassen von Emotionen (0-6) enthält.\n",
    "\n",
    "Das Dataset wurde von mir in einem passenden Format vorbereitet, damit es direkt in PyTorch verwendet werden kann. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff63be",
   "metadata": {},
   "source": [
    "## Ablauf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866bbff1",
   "metadata": {},
   "source": [
    "<img src=\"images/cnn2_process.png\" alt=\"CNN Process\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e1dac8",
   "metadata": {},
   "source": [
    "## FER-2013 Dataset vorbereiten, laden und visualisieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5032974d",
   "metadata": {},
   "source": [
    "Das FER-2013 Dataset enthält Bilder von Gesichtern, die in verschiedene Emotionen klassifiziert sind. Es ist ein häufig verwendetes Dataset für die Gesichtsemotionserkennung. \n",
    "In diesem Abschnitt werden wir das Dataset vorbereiten, laden und einige Beispiele visualisieren.\n",
    "\n",
    "Ausserdem prüfen wir wie im letzten Notebook die Daten auf mögliche Probleme.\n",
    "\n",
    "*Datasetquelle: https://www.kaggle.com/datasets/msambare/fer2013*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dfa844",
   "metadata": {},
   "source": [
    "### Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f855ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"datasets/FER-2013/\"\n",
    "data_train_path = os.path.join(data_path, \"train\")\n",
    "data_test_path = os.path.join(data_path, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e09d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = torch.load(os.path.join(data_train_path, \"train_images.pt\"))\n",
    "train_labels = torch.load(os.path.join(data_train_path, \"train_labels.pt\"))\n",
    "test_images = torch.load(os.path.join(data_test_path, \"test_images.pt\"))\n",
    "test_labels = torch.load(os.path.join(data_test_path, \"test_labels.pt\"))\n",
    "\n",
    "\n",
    "label_mapping = {\n",
    "    'angry': 0,\n",
    "    'disgust': 1,\n",
    "    'fear': 2,\n",
    "    'happy': 3,\n",
    "    'sad': 4,\n",
    "    'surprise': 5,\n",
    "    'neutral': 6\n",
    "}\n",
    "\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8b577b",
   "metadata": {},
   "source": [
    "### Beispielbilder aus dem FER-2013 Dataset visualisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6da6b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 Beispiele plotten\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    random_index = random.randint(0, len(train_images) - 1)\n",
    "    ax = axes[i // 5, i % 5]\n",
    "    ax.imshow(train_images[random_index].squeeze(), cmap='gray')\n",
    "    ax.set_title(f\"Label: {reverse_label_mapping[train_labels[random_index].item()]}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea9f364",
   "metadata": {},
   "source": [
    "### Daten validieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a5cfe",
   "metadata": {},
   "source": [
    "Damit wir die Daten benutzen können, müssen alle Daten gleich formiert sein. Das heisst alle Bilder müssen die gleiche Grösse haben und die Pixelwerte müssen im gleichen Bereich liegen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ccbc96",
   "metadata": {},
   "source": [
    "#### Pixelwerte überprüfen\n",
    "\n",
    "In diesem Abschnitt prüfen wir, ob es verschiedene Bildgrössen gibt, ob alle Pixelwerte von 0 bis 255 reichen und zeigen ein Beispiel eines Bildes an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa778bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Anzahl Trainings- und Testdaten anzeigen\n",
    "print(f\"Anzahl Trainingsbilder: {len(train_images)}\")\n",
    "print(f\"Anzahl Testbilder: {len(test_images)}\")\n",
    "\n",
    "# Prüfe ob alle Bilder die gleiche Größe haben. Die Bilder sind als Tensoren gespeichert, daher können wir die Form der Tensoren überprüfen.\n",
    "image_shapes = [image.shape for image in train_images]\n",
    "unique_shapes = set(image_shapes)\n",
    "print(f\"Einzigartige Bildgrößen: {unique_shapes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78296738",
   "metadata": {},
   "source": [
    "#### Prüfen der Pixelwerte\n",
    "\n",
    "Wir prüfen ob alle Pixelwerte im Bereich von 0 bis 255 liegen. Dies ist wichtig, damit die Bilder korrekt normalisiert werden können und damit das Modell korrekt lernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761b51c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prüfen, dass die Pixelwerte im Bereich von 0 bis 255 liegen. Die Bilder sind als Tensoren gespeichert.\n",
    "# Wir prüfen die Pixelwerte für alle Bilder, indem wir die Werte der Tensoren extrahieren und in eine flache Liste umwandeln.\n",
    "temp_train_images_np = train_images.numpy()\n",
    "assert np.all(temp_train_images_np >= 0) and np.all(temp_train_images_np <= 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a031309",
   "metadata": {},
   "source": [
    "#### Klassenverteilung und die Labels überprüfen\n",
    "Wir überprüfen ob alle Klassen sowohl in den Trainings- als auch in den Testdaten vorhanden sind. Es ist wichtig, dass alle Klassen in beiden Datensätzen vertreten sind, damit das Modell lernen kann, alle Klassen zu erkennen und generalisieren kann. Auch prüfen wir, ob keine falschen Labels vorhanden sind, also ob alle Labels tatsächlich zwischen 0 und 6 liegen.\n",
    "\n",
    "Die Klassenverteilung gibt an, wie viele Bilder es von jeder Klasse (Emotion) im Dataset gibt. Es ist wichtig, die Klassenverteilung zu überprüfen, um sicherzustellen, dass das Dataset ausgewogen ist und keine Klasse überrepräsentiert oder unterrepräsentiert ist. Eine unausgewogene Klassenverteilung kann zu einem Modell führen, das schlecht generalisiert und eine schlechte Leistung auf den Testdaten erzielt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a4dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels überprüfen\n",
    "list_train_labels = [int(label.item()) for label in train_labels]\n",
    "list_test_labels = [int(label.item()) for label in test_labels]\n",
    "print(f\"Einzigartige Labels im Training: {set(list_train_labels)}\")\n",
    "print(f\"Einzigartige Labels im Testing: {set(list_test_labels)}\")\n",
    "\n",
    "\n",
    "# Klassenverteilung überprüfen\n",
    "print(\"-\" * 50)\n",
    "train_label_counts = pd.Series(list_train_labels).value_counts().sort_index()\n",
    "test_label_counts = pd.Series(list_test_labels).value_counts().sort_index()\n",
    "\n",
    "print(\"Klassenverteilung:\")\n",
    "for label, count in train_label_counts.items():\n",
    "    print(f\"Label {reverse_label_mapping[label]}: {count} Trainingsbilder, {test_label_counts[label]} Testbilder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89580185",
   "metadata": {},
   "source": [
    "### Aufgabe 1: Weitere Validierungsschritte\n",
    "\n",
    "Auch weitere Validierungsschritte sollten durchgeführt werden.\n",
    "\n",
    "Prüfen Sie mit Hilfe der Anzeige der Stichproben einige Zellen weiter oben folgende Schritte:\n",
    "\n",
    "- Sind die Klassen einigermassen gleich verteilt?\n",
    "\n",
    "> \n",
    "\n",
    "- Sind alle Klassen in den Trainings- und Testdaten vorhanden?\n",
    "\n",
    "> \n",
    "\n",
    "- Gibt es fehlende Werte (z.B. auch leere Bilder)? Wie könnten Sie dies feststellen?\n",
    "\n",
    "> \n",
    "\n",
    "- Sind auf allen Bildern tatsächlich Gesichter zu sehen?\n",
    "\n",
    "> \n",
    "\n",
    "- Sind die Ausschnitte der Bilder sinnvoll und ähnlich (z.B. alle Bilder zeigen das Gesicht von vorne, oder gibt es auch Bilder von der Seite)?\n",
    "\n",
    "> \n",
    "\n",
    "- Weshalb prüfen wir die Klassenverteilung?\n",
    "> \n",
    "\n",
    "- Was wäre ein Data Bias der in einem solchen Datensatz auftreten könnte?\n",
    "> \n",
    "\n",
    "- Welche Datenqualitätskriterien haben wir überprüft? Zur Erinnerung nochmals die Liste:\n",
    "    Vollständigkeit, Konsistenz, - Richtigkeit, - Einzigartigkeit, - Aktualität\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea209be4",
   "metadata": {},
   "source": [
    "### Data Loader erstellen\n",
    "\n",
    "In diesem Abschnitt erstellen wir einen Data Loader, um die Daten in Batches zu laden und für das Training vorzubereiten. \n",
    "Die Daten sind bereits in Trainings- und Testset aufgeteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42b2bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Da die Bilder in einem eigenen Format vorliegen, normalisieren wir die Pixelwerte manuell, indem wir die Pixelwerte durch 255 teilen, um sie in den Bereich von 0 bis 1 zu bringen. Dies ist wichtig, damit das Training stabiler und schneller lernt.\n",
    "\n",
    "# Wir müssen hier die Bilder normalisieren, da die Pixelwerte im Bereich 0 bis 255 liegen. Wir teilen die Pixelwerte dementsprechend durch 255.\n",
    "train_images_tensors = train_images.float() / 255.0\n",
    "test_images_tensors = test_images.float() / 255.0\n",
    "\n",
    "# Data Loader erstellen\n",
    "train_loader = DataLoader(list(zip(train_images_tensors, train_labels)), batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(list(zip(test_images_tensors, test_labels)), batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b3bce1",
   "metadata": {},
   "source": [
    "## Neural Network Architektur definieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c99218",
   "metadata": {},
   "source": [
    "In diesem Abschnitt definieren wir die Architektur unseres Convolutional Neural Networks. \n",
    "\n",
    "Wir werden mehrere Convolutional Layers, Pooling Layers und Fully Connected Layers verwenden, um ein Modell zu erstellen, das in der Lage ist, die Bilder im FER-2013-Datensatz zu klassifizieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3dca6",
   "metadata": {},
   "source": [
    "### Berechnung der Dimensionen der verschiedenen Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d877e6",
   "metadata": {},
   "source": [
    "In pyTorch müssen wir die Dimensionen der Daten durch die verschiedenen Schichten unseres Netzwerks verfolgen, um die Dimensionen der einzelnen Layers zu konfigurieren.\n",
    "\n",
    "In diesem Abschnitt berechnen wir die Dimensionen der Daten nach jeder Schicht in unserem CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139583f1",
   "metadata": {},
   "source": [
    "#### Aufgabe 2\n",
    "\n",
    "Wir möchten folgende Architektur für unser CNN verwenden:\n",
    "```\n",
    "Input (48x48) --> Conv1 (7x7, 12 Kernel, Stride 1, Padding 0) --> Pool1 (2x2, Stride 2) --> Conv2 (5x5, 16 Kernel, Stride 1, Padding 0) --> Pool2 (2x2, Stride 2) --> Flatten --> Fully Connected Layer\n",
    "```\n",
    "\n",
    "1. Berechnen Sie die Bildgrösse nach dem ersten Convolutional Layer:\n",
    "\n",
    "> Hinweis: Überlegen Sie sich wie sich die Bildgrösse mit dem verwendeten Kernel, Padding und Stride verändert.\n",
    "\n",
    "> \n",
    "\n",
    "2. Berechnen Sie die Bildgrösse nach dem ersten Pooling Layer:\n",
    "> \n",
    "\n",
    "3. Berechnen Sie die Bildgrösse nach dem zweiten Convolutional Layer:\n",
    "> \n",
    "\n",
    "4. Berechnen Sie die Bildgrösse nach dem zweiten Pooling Layer:\n",
    "> \n",
    "\n",
    "5. Wie viele Neuronen muss der Fully Connected Layer haben, um die Daten korrekt zu verarbeiten? (Tipp: wir müssen die Anzahl der Kanäle und die Bildgrösse nach dem letzten Pooling Layer berücksichtigen)\n",
    "\n",
    "> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48608e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO erstellen Sie mit torch.nn.sequential ein Convolutional Neural Network mit folgenden Schichten:\n",
    "# - Convolutional Layer mit einem Eingabe-Kanal, 12 Ausgabekanälen, einem Kernel von 7x7, einem Stride von 1 und einem Padding von 0\n",
    "# - Max Pooling Layer mit einem Kernel von 2x2 und einem Stride von 2\n",
    "# - LeakyRELU Aktivierungsfunktion\n",
    "# - Convolutional Layer mit 12 Eingabekanälen, 16 Ausgabekanälen, einem Kernel von 5x5, einem Stride von 1 und einem Padding von 2\n",
    "# - Max Pooling Layer mit einem Kernel von 2x2 und einem Stride von 2\n",
    "# - LeakyRELU Aktivierungsfunktion\n",
    "# - Flatten Layer, um die Daten für den Fully Connected Layer vorzubereiten\n",
    "# - Fully Connected Layer mit der Anzahl Eingabeneuronen die Sie oben berechnet haben und 10 Ausgabeneuronen.\n",
    "\n",
    "model_1 = torch.nn.Sequential(\n",
    "...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a72bc85",
   "metadata": {},
   "source": [
    "## Netzwerk trainieren und evaluieren\n",
    "In diesem Abschnitt trainieren wir unser CNN mit dem MNIST-Datensatz und evaluieren die Leistung des Modells auf dem Testset. Wir werden die Trainings- und Testgenauigkeit berechnen und die Ergebnisse visualisieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3164ac6",
   "metadata": {},
   "source": [
    "### Trainingloop\n",
    "\n",
    "Die Funktion `train_model` trainiert das CNN über eine bestimmte Anzahl von Epochen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304baf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, optimizer, loss_fn, max_num_epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(max_num_epochs):\n",
    "        batch_train_losses = []\n",
    "        batch_test_losses = []\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch\n",
    "\n",
    "            # Wir verschieben die Bilder und Labels auf die gleiche Hardware wie das Modell (CPU oder GPU)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Wir setzen den Gradienten zurück für den Forward- und Backward-Pass\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Wir berechnen die Vorhersagen des Modells für die aktuellen Bilder\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Wir berechnen den Loss\n",
    "            train_loss = loss_fn(outputs, labels)\n",
    "\n",
    "            #Wir berechnen die Gradienten und aktualisieren die Gewichte des Modells\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch_train_losses.append(train_loss.item())\n",
    "\n",
    "        # Testing Loop mit torch.no_grad(), damit wir keine Gradienten berechnen und somit Speicher sparen\n",
    "        # Wir berechnen den Testloss für die Testdaten aus dem test_loader\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                images, labels = batch\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                batch_test_losses.append(loss_fn(outputs, labels).item())\n",
    "\n",
    "        training_loss = np.mean(batch_train_losses)\n",
    "        testing_loss = np.mean(batch_test_losses)\n",
    "        train_losses.append(training_loss)\n",
    "        test_losses.append(testing_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch}: Train Loss = {training_loss:.5f}, Test Loss = {testing_loss:.5f}\")\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce74f50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_test_losses(train_losses, test_losses):\n",
    "    # Test und Trainingsverluste visualisieren\n",
    "    plt.plot(train_losses, label='Trainings Loss')\n",
    "    plt.plot(test_losses, label='Test Loss')\n",
    "    plt.xlabel('Epochen')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Trainings- und Testverlust über Epochen')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faba0a4d",
   "metadata": {},
   "source": [
    "### Modell Trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1368f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter definieren\n",
    "max_num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Optimizer und die Loss-Funktion definieren\n",
    "optimizer = torch.optim.Adam(model_1.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Das Modell muss noch auf die Hardware verschoben werden.\n",
    "model_1.to(device)\n",
    "\n",
    "train_losses, test_losses = train_model(model_1, train_loader, test_loader, optimizer, loss_fn, max_num_epochs)\n",
    "\n",
    "# Speichern des trainierten Modells\n",
    "torch.save(model_1.state_dict(), \"FER_cnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d13ce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_test_losses(train_losses,test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3118481a",
   "metadata": {},
   "source": [
    "#### Aufgabe 2.1: Fragen zu den Lernkurven im Plot\n",
    "Was schliessen Sie aus diesen beiden Lernkurven im Plot?\n",
    "\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f05280",
   "metadata": {},
   "source": [
    "### Modell laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2abe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_geladen = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels=1, out_channels=12, kernel_size=7, stride=1, padding=0),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Conv2d(in_channels=12, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(in_features=16*8*8, out_features=7),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Testen ob das File für das Modell existiert und das Modell geladen werden kann\n",
    "if os.path.exists(\"FER_cnn.pth\"):\n",
    "    model_1_geladen.load_state_dict(torch.load(\"FER_cnn.pth\"))\n",
    "    print(\"Modell erfolgreich geladen!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0933d0",
   "metadata": {},
   "source": [
    "### Funktion um die Modell-Accuracy zu berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065b653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy berechnen\n",
    "\n",
    "def test_model_accuracy(model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            images, labels = batch\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ef099",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test Accuracy: {test_model_accuracy(model_1_geladen, test_loader):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14732a46",
   "metadata": {},
   "source": [
    "## Alternative Modelle erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eea6ec8",
   "metadata": {},
   "source": [
    "### Aufgabe 3: Andere Modelle erstellen und evaluieren\n",
    "\n",
    "In diesem Abschnitt erstellen Sie zwei weitere Modelle mit unterschiedlichen Architekturen und vergleichen Sie die Leistung dieser Modelle mit dem ursprünglichen Modell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42000395",
   "metadata": {},
   "source": [
    "#### Modell 2 erstellen, trainieren und speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a0fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell 2: Erstellen Sie ein tieferes CNN mit mehr Filtern und mehr linearen Layers nacheinander. \n",
    "# Achten Sie jedoch darauf, dass die Anzahl der Parameter nicht zu gross wird, da ansonsten das Training zu lange dauert.\n",
    "model_2 = torch.nn.Sequential(\n",
    "... # TODO Model 2 Architektur hier definieren\n",
    ")\n",
    "\n",
    "print(\"Modell 2 Architektur:\")\n",
    "print(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a54876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell 2 trainieren\n",
    "model_2.to(device)\n",
    "optimizer_2 = torch.optim.Adam(model_2.parameters(), lr=learning_rate)\n",
    "loss_fn_2 = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"\\n=== Training Modell 2 ===\")\n",
    "train_losses_2, test_losses_2 = train_model(model_2, train_loader, test_loader, optimizer_2, loss_fn_2, max_num_epochs)\n",
    "\n",
    "# Modell 2 speichern\n",
    "torch.save(model_2.state_dict(), \"FER_cnn_model_2.pth\")\n",
    "print(\"Modell 2 gespeichert!\")\n",
    "\n",
    "plot_train_test_losses(train_losses_2,test_losses_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b400bc11",
   "metadata": {},
   "source": [
    "**Oben:** In diesem Diagramm sehen wir wie das Modell extrem auf die Trainingsdaten overfitted und auf den Testdaten wieder schlechter wird."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b6e445",
   "metadata": {},
   "source": [
    "#### Modell 3 erstellen, trainieren und speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce68d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell 3: Ein kompakteres CNN mit weniger Filtern und kleineren Kernel und einem Linear Layer. \n",
    "# Eine Andere Aktivierungsfunktion z.B.torch.nn.Sigmoid() oder torch.nn.Tanh() könnte hier verwendet werden. \n",
    "model_3 = torch.nn.Sequential(\n",
    "...# TODO Modell 3 Architektur hier definieren.\n",
    ")\n",
    "\n",
    "print(\"Modell 3 Architektur:\")\n",
    "print(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9037c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell 3 trainieren\n",
    "model_3.to(device)\n",
    "optimizer_3 = torch.optim.Adam(model_3.parameters(), lr=learning_rate)\n",
    "loss_fn_3 = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"\\n=== Training Modell 3 ===\")\n",
    "train_losses_3, test_losses_3 = train_model(model_3, train_loader, test_loader, optimizer_3, loss_fn_3, max_num_epochs)\n",
    "\n",
    "# Modell 3 speichern\n",
    "torch.save(model_3.state_dict(), \"FER_cnn_model_3.pth\")\n",
    "print(\"Modell 3 gespeichert!\")\n",
    "\n",
    "# Visualisierung der Trainings- und Testverluste\n",
    "plot_train_test_losses(train_losses_3,test_losses_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4c82bd",
   "metadata": {},
   "source": [
    "**Oben:** In diesem Diagramm sehen wir wie das Modell auf den Trainingsdaten Underfitted. Das Training ist noch nicht abgeschlossen da es zwar einen Abwärtstrend in der Trainings und der Testkurve gibt, aber beide Kurven noch relativ hoch und beieinander liegen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd449a2b",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; border: 5px solid #a10000ff;\">\n",
    "<h2 style=\"color: red;\">Behalten Sie die Dateien (.pth) der drei gespeicherten Modelle für nächste Woche!</h2>\n",
    "\n",
    "Wir werden die Modelle nächste Woche, genauer auswerten und benötigen deshalb die Modelle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b212092",
   "metadata": {},
   "source": [
    "### Auswertung der Modelle anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca841005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Modelle laden und Accuracy vergleichen\n",
    "print(\"\\n=== Laden und Evaluieren aller Modelle ===\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Modell 1 laden\n",
    "# ----------------------------------------------------------------------\n",
    "model_1_final = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels=1, out_channels=12, kernel_size=7, stride=1, padding=0),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Conv2d(in_channels=12, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(in_features=16*8*8, out_features=7),\n",
    ")\n",
    "if os.path.exists(\"FER_cnn.pth\"):\n",
    "    model_1_final.load_state_dict(torch.load(\"FER_cnn.pth\"))\n",
    "    model_1_final.to(device)\n",
    "    accuracy_1 = test_model_accuracy(model_1_final, test_loader)\n",
    "    print(f\"Modell 1 Test Accuracy: {accuracy_1:.2f}%\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Modell 2 laden\n",
    "# ----------------------------------------------------------------------\n",
    "model_2_final = torch.nn.Sequential(\n",
    "    ...#TODO Model 2 Architektur hier einfügen\n",
    ")\n",
    "if os.path.exists(\"FER_cnn_model_2.pth\"):\n",
    "    model_2_final.load_state_dict(torch.load(\"FER_cnn_model_2.pth\"))\n",
    "    model_2_final.to(device)\n",
    "    accuracy_2 = test_model_accuracy(model_2_final, test_loader)\n",
    "    print(f\"Modell 2 Test Accuracy: {accuracy_2:.2f}%\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Modell 3 laden\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "model_3_final = torch.nn.Sequential(\n",
    "    ...#TODO Model 3 Architektur hier einfügen\n",
    ")\n",
    "if os.path.exists(\"FER_cnn_model_3.pth\"):\n",
    "    model_3_final.load_state_dict(torch.load(\"FER_cnn_model_3.pth\"))\n",
    "    model_3_final.to(device)\n",
    "    accuracy_3 = test_model_accuracy(model_3_final, test_loader)\n",
    "    print(f\"Modell 3 Test Accuracy: {accuracy_3:.2f}%\")\n",
    "\n",
    "# Vergleich visualisieren\n",
    "print(\"\\n=== Zusammenfassung ===\")\n",
    "accuracies = [accuracy_1, accuracy_2, accuracy_3]\n",
    "models = ['Modell 1', 'Modell 2', 'Modell 3']\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(models, accuracies, color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "plt.title('Vergleich der Test Accuracy aller Modelle', fontsize=14)\n",
    "plt.ylim([0, 100])\n",
    "for i, v in enumerate(accuracies):\n",
    "    plt.text(i, v + 2, f'{v:.2f}%', ha='center', fontsize=11, fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b716073",
   "metadata": {},
   "source": [
    "## Optional: Aufgabe 4 mit Grid-Search für Hyperparameter\n",
    "In diesem Abschnitt können Sie eine Grid-Search durchführen, um die besten Hyperparameter für Ihr Modell zu finden. Sie können verschiedene Werte für die Lernrate, die Anzahl der Epochen, die Batch-Grösse und andere Hyperparameter ausprobieren und die Leistung des Modells vergleichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45928b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.001, 0.0005, 0.0001]\n",
    "number_of_epochs = [5, 10, 20]\n",
    "\n",
    "# Wichtig: Um faire Vergleiche zu ermöglichen, erstellen wir für jede Kombination ein neues Modell (anstatt ein bereits trainiertes Modell weiterzutrainieren)\n",
    "\n",
    "print(\"=== Grid Search für Modell 1 Hyperparameter ===\\n\")\n",
    "print(f\"Teste {len(learning_rates)} Learning Rates: {learning_rates}\")\n",
    "print(f\"Teste {len(number_of_epochs)} Epochenzahlen: {number_of_epochs}\")\n",
    "print(f\"Gesamtanzahl Kombinationen: {len(learning_rates) * len(number_of_epochs)}\\n\")\n",
    "\n",
    "# Dictionary um die Ergebnisse zu speichern\n",
    "results = []\n",
    "\n",
    "# Durchlaufe alle Kombinationen von Hyperparametern\n",
    "for lr in learning_rates:\n",
    "    for epochs in number_of_epochs:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Training mit: Learning Rate = {lr}, Epochs = {epochs}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Erstelle ein neues Modell für jede Kombination (wichtig für faire Vergleiche!)\n",
    "        model_grid = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=12, kernel_size=7, stride=1, padding=0),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(in_channels=12, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(in_features=16*8*8, out_features=7),\n",
    "        )\n",
    "        \n",
    "        # Modell auf Device verschieben\n",
    "        model_grid.to(device)\n",
    "        \n",
    "        # Optimizer und Loss-Funktion mit aktuellen Hyperparametern\n",
    "        optimizer_grid = torch.optim.Adam(model_grid.parameters(), lr=lr)\n",
    "        loss_fn_grid = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Modell trainieren\n",
    "        train_losses_grid, test_losses_grid = train_model(\n",
    "            model_grid, train_loader, test_loader, optimizer_grid, loss_fn_grid, epochs\n",
    "        )\n",
    "        \n",
    "        # Test Accuracy berechnen\n",
    "        model_grid.eval()  # Setze Modell in Evaluation Mode\n",
    "        accuracy = test_model_accuracy(model_grid, test_loader)\n",
    "        \n",
    "        # Finaler Loss (der letzten Epoche)\n",
    "        final_train_loss = train_losses_grid[-1]\n",
    "        final_test_loss = test_losses_grid[-1]\n",
    "        \n",
    "        # Ergebnisse speichern\n",
    "        results.append({\n",
    "            'learning_rate': lr,\n",
    "            'epochs': epochs,\n",
    "            'accuracy': accuracy,\n",
    "            'final_train_loss': final_train_loss,\n",
    "            'final_test_loss': final_test_loss,\n",
    "            'train_losses': train_losses_grid,\n",
    "            'test_losses': test_losses_grid\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nErgebnis: Test Accuracy = {accuracy:.2f}%\")\n",
    "        print(f\"Final Train Loss = {final_train_loss:.5f}, Final Test Loss = {final_test_loss:.5f}\")\n",
    "\n",
    "# Finde die beste Kombination basierend auf Test Accuracy\n",
    "best_result = max(results, key=lambda x: x['accuracy'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"=== GRID SEARCH ZUSAMMENFASSUNG ===\")\n",
    "print(\"=\"*60)\n",
    "print(\"Alle getesteten Kombinationen:\")\n",
    "print(f\"{'LR':<12} {'Epochs':<10} {'Accuracy':<12} {'Train Loss':<12} {'Test Loss':<12}\")\n",
    "print(\"-\" * 60)\n",
    "for r in results:\n",
    "    print(f\"{r['learning_rate']:<12} {r['epochs']:<10} {r['accuracy']:<12.2f} {r['final_train_loss']:<12.5f} {r['final_test_loss']:<12.5f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BESTE HYPERPARAMETER:\")\n",
    "print(f\"  Learning Rate: {best_result['learning_rate']}\")\n",
    "print(f\"  Epochs: {best_result['epochs']}\")\n",
    "print(f\"  Test Accuracy: {best_result['accuracy']:.2f}%\")\n",
    "print(f\"  Final Test Loss: {best_result['final_test_loss']:.5f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualisierung der Ergebnisse\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Accuracy für verschiedene Kombinationen\n",
    "accuracies = [r['accuracy'] for r in results]\n",
    "labels = [f\"LR={r['learning_rate']}\\nE={r['epochs']}\" for r in results]\n",
    "colors = ['green' if r == best_result else 'steelblue' for r in results]\n",
    "\n",
    "axes[0].bar(range(len(results)), accuracies, color=colors)\n",
    "axes[0].set_xticks(range(len(results)))\n",
    "axes[0].set_xticklabels(labels, rotation=45, ha='right')\n",
    "axes[0].set_ylabel('Test Accuracy (%)')\n",
    "axes[0].set_title('Grid Search Ergebnisse: Test Accuracy')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "axes[0].axhline(y=best_result['accuracy'], color='red', linestyle='--', \n",
    "                label=f\"Best: {best_result['accuracy']:.2f}%\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot 2: Train vs Test Loss für beste Konfiguration\n",
    "axes[1].plot(best_result['train_losses'], label='Train Loss', linewidth=2)\n",
    "axes[1].plot(best_result['test_losses'], label='Test Loss', linewidth=2)\n",
    "axes[1].set_xlabel('Epochs')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title(f'Beste Konfiguration: LR={best_result[\"learning_rate\"]}, Epochs={best_result[\"epochs\"]}')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Bestes Modell nochmals trainieren und speichern\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"(Setzen Sie save_best_model = True um das Modell zu speichern)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "\n",
    "save_best_model = False  # Ändern Sie dies auf True, um das beste Modell zu speichern\n",
    "\n",
    "if save_best_model:\n",
    "    print(\"\\nTrainiere bestes Modell neu...\")\n",
    "    final_best_model = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(in_channels=1, out_channels=12, kernel_size=7, stride=1, padding=0),\n",
    "        torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Conv2d(in_channels=12, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
    "        torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(in_features=16*8*8, out_features=7),\n",
    "    )\n",
    "    final_best_model.to(device)\n",
    "    \n",
    "    optimizer_best = torch.optim.Adam(final_best_model.parameters(), lr=best_result['learning_rate'])\n",
    "    loss_fn_best = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_model(final_best_model, train_loader, test_loader, optimizer_best, loss_fn_best, best_result['epochs'])\n",
    "    \n",
    "    torch.save(final_best_model.state_dict(), \"FER_cnn_best_gridsearch.pth\")\n",
    "    print(f\"Bestes Modell gespeichert als: FER_cnn_best_gridsearch.pth\")\n",
    "    print(f\"Verwendete Hyperparameter: LR={best_result['learning_rate']}, Epochs={best_result['epochs']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "praktikum_ef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
