{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b9880fe",
   "metadata": {},
   "source": [
    "# Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa9d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055839ec",
   "metadata": {},
   "source": [
    "## Softmax-Funktion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de600c4",
   "metadata": {},
   "source": [
    "Die Softmax-Funktion ist eine mathematische Funktion, die in der Regel in der letzten Schicht eines neuronalen Netzwerks verwendet wird, insbesondere bei Klassifikationsproblemen. Sie nimmt einen Vektor von Rohwerten (Logits) und transformiert ihn in einen Vektor von Wahrscheinlichkeiten, wobei die Summe aller Wahrscheinlichkeiten gleich 1 ist.\n",
    "\n",
    "Gegeben sei ein Vektor von Ausgaben des neuronalen Netzwerkes $ z = (z_1, z_2, \\ldots, z_n) $,\n",
    "Die Funktion wird wie folgt definiert:\n",
    "$$\n",
    "\\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}}\n",
    "$$\n",
    "\n",
    "In Worten ausgedrückt: Für jedes Element $ z_i $ im Vektor $ z $ berechnet die Softmax-Funktion den Exponentialwert von $ z_i $ und teilt diesen durch die Summe der Exponentialwerte aller Elemente im Vektor.\n",
    "\n",
    "\n",
    "**Vorteile der Softmax-Funktion:**\n",
    "- **Wahrscheinlichkeitsverteilung**: Die Softmax-Funktion transformiert die Ausgaben des Modells in eine Wahrscheinlichkeiten, was es einfacher macht, die Vorhersagen zu interpretieren.\n",
    "- **Ableitbarkeit**: Die Softmax-Funktion ist ableitbar, was es ermöglicht, sie in Backpropagation zu verwenden, um die Gewichte des Modells zu aktualisieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e518e06",
   "metadata": {},
   "source": [
    "### Torch vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ca290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir prüfen ob eine Hardwarebeschleunigung möglich ist und verwenden diese, wenn sie verfügbar ist\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "torch.manual_seed(42) # Setze den Zufallsseed für Reproduzierbarkeit\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e1dac8",
   "metadata": {},
   "source": [
    "## MNIST Dataset vorbereiten, laden und visualisieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936bcff0",
   "metadata": {},
   "source": [
    "Wir nutzen für dieses Notebook den MNIST-Datensatz, der handgeschriebene Ziffern enthält. Die Ziffern sind in 10 Klassen (0-9) unterteilt, und jede Klasse enthält Tausende von Bildern. \n",
    "Die Bilder sind in Graustufen und haben eine Auflösung von 28x28 Pixeln.\n",
    "Das Modell muss lernen, diese Ziffern korrekt zu klassifizieren.\n",
    "\n",
    "Wir werden diesen Datensatz laden, vorbereiten und einige Beispiele visualisieren. Der Datensatz kann direkt von PyTorch heruntergeladen werden, was den Prozess vereinfacht.\n",
    "\n",
    "Quelle Dataset: [MNIST Dataset](https://pytorch.org/vision/stable/datasets.html#mnist)\n",
    "\n",
    "Originale nicht mehr existierende Webseite: [MNIST Dataset](http://yann.lecun.com/exdb/mnist/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f855ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mnist Dataset laden\n",
    "mnist_train = torchvision.datasets.MNIST(root='datasets', train=True, download=True)\n",
    "mnist_test = torchvision.datasets.MNIST(root='datasets', train=False, download=True)\n",
    "\n",
    "# Damit wir die Bilder in einem CNN verwenden können, müssen wir die Bilder in Tensoren umwandeln.\n",
    "\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "# Mit der Bibliothek Torchvision können wird das MNIST Dataset direkt herunterladen und in einem Schritt in Tensoren umwandeln. \n",
    "# Train=True lädt den Trainingsdatensatz, Train=False lädt den Testdatensatz.\n",
    "mnist_transformed_train = torchvision.datasets.MNIST(root='datasets', train=True, download=True, transform=transform)\n",
    "mnist_transformed_test = torchvision.datasets.MNIST(root='datasets', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(mnist_transformed_train, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(mnist_transformed_test, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e356c8",
   "metadata": {},
   "source": [
    "### Modell erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48608e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO erstellen Sie mit torch.nn.sequential ein Convolutional Neural Network mit folgenden Schichten. Die Schichten werden als einzelne Parameter an torch.nn.Sequential übergeben.\n",
    "# - Convolutional Layer mit einem Eingabe-Kanal, 12 Ausgabekanälen, einem Kernel von 7x7, einem Stride von 1 und einem Padding von 0\n",
    "# - Max Pooling Layer mit einem Kernel von 2x2 und einem Stride von 2\n",
    "# - RELU Aktivierungsfunktion\n",
    "# - Convolutional Layer mit 12 Eingabekanälen, 16 Ausgabekanälen, einem Kernel von 5x5, einem Stride von 1 und einem Padding von 2\n",
    "# - Max Pooling Layer mit einem Kernel von 2x2 und einem Stride von 2\n",
    "# - RELU Aktivierungsfunktion\n",
    "# - Flatten Layer, um die Daten für die Fully Connected Layer vorzubereiten\n",
    "# - Fully Connected Layer mit der Anzahl Eingabeneuronen die Sie oben berechnet haben und 10 Ausgabeneuronen.\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels=1, out_channels=12, kernel_size=7, stride=1, padding=0),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(in_channels=12, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(in_features=16*5*5, out_features=10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3164ac6",
   "metadata": {},
   "source": [
    "### Netzwerk trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304baf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testen ob das File für das Modell existiert und das Modell geladen werden kann, ansonsten wird das Modell trainiert und gespeichert.\n",
    "if os.path.exists(\"mnist_cnn.pth\"):\n",
    "    model.load_state_dict(torch.load(\"mnist_cnn.pth\"))\n",
    "    print(\"Modell erfolgreich geladen!\")\n",
    "else:\n",
    "    # Hyperparameter definieren\n",
    "    max_num_epochs = 10\n",
    "    learning_rate = 0.001\n",
    "    momentum = 0.9\n",
    "\n",
    "    # Optimizer und die Loss-Funktion definieren\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    # Das Modell muss noch auf die Hardware verschoben werden.\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(max_num_epochs):\n",
    "        batch_train_losses = []\n",
    "        batch_test_losses = []\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch\n",
    "\n",
    "            # Wir verschieben die Bilder und Labels auf die gleiche Hardware wie das Modell (CPU oder GPU)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # TODO vervollständigen Sie hier die nötigen Schritte, um das Modell zu trainieren\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            train_loss = loss(outputs, labels)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_train_losses.append(train_loss.item())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                images, labels = batch\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                batch_test_losses.append(loss(outputs, labels).item())\n",
    "\n",
    "        training_loss = np.mean(batch_train_losses)\n",
    "        testing_loss = np.mean(batch_test_losses)\n",
    "        train_losses.append(training_loss)\n",
    "        test_losses.append(testing_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch}: Train Loss = {training_loss:.5f}, Test Loss = {testing_loss:.5f}\")\n",
    "\n",
    "    # Modell speichern\n",
    "    torch.save(model.state_dict(), 'mnist_cnn.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52674c60",
   "metadata": {},
   "source": [
    "### Aufgabe 1: Ausgaben des Modells interpretieren\n",
    "\n",
    "Die \"Roh-Ausgaben\" eines Modells werden Logits genannt. Sie sind die direkten Ausgaben der letzten Schicht eines neuronalen Netzwerks, bevor z.B. eine Softmax-Funktion angewendet wird. Logits können positive oder negative Werte annehmen und geben an, wie stark das Modell glaubt, dass ein bestimmtes Bild zu einer bestimmten Klasse gehört. Je höher der Logit-Wert, desto stärker ist die Vorhersage für diese Klasse.\n",
    "\n",
    "\n",
    "1. Inspizieren Sie die Ausgaben des Modells für das erste Bild im Batch. Was stellen diese Werte dar? Wie können sie interpretiert werden?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327adf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch aus dem Testloader nehmen und die Ausgaben des Modells für diesen Batch berechnen. Wir verwenden hier den Testloader, damit wir die Ausgaben des Modells mit den Labels vergleichen können.\n",
    "with torch.no_grad():\n",
    "    for image, target in test_loader:\n",
    "        image, target = image.to(device), target.to(device)\n",
    "        outputs = model(image)\n",
    "        break\n",
    "\n",
    "print(f\"Das Label für das Sample ist: {target[0].item()}\\n\") \n",
    "\n",
    "# Outputs für das erste Bild im Batch\n",
    "for i in range(10):\n",
    "    print(f\"Vorhersage für Klasse {i}: {outputs[0][i].item():5f}\")\n",
    "\n",
    "# Bild anzeigen\n",
    "plt.imshow(image[0].cpu().squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c3a6bd",
   "metadata": {},
   "source": [
    "### Aufgabe 2: Softmax anwenden\n",
    "\n",
    "1. Wir wenden die Softmax-Funktion auf die Ausgaben des Modells anwenden, um die Wahrscheinlichkeiten für jede Klasse zu berechnen. Welcher Wert im Vergleich zu den Ausgabewerten (Logits) in Aufgabe 1 hat die höchste Wahrscheinlichkeit? \n",
    "\n",
    "\n",
    "2. Wie verhalten sich die Wahrscheinlichkeiten der anderen Klassen im Vergleich dazu? Ist das Verhältnis der Unterschiede zwischen den Logit-Werten und den Wahrscheinlichkeiten der Klassen intuitiv verständlich?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0146c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Das Label für das Sample ist: {target[0].item()}\\n\") \n",
    "\n",
    "softmax = torch.nn.Softmax(dim=0)\n",
    "probabilities = softmax(outputs[0])\n",
    "probabilities = probabilities.cpu().numpy().round(7)\n",
    "for i in range(10):\n",
    "    print(f\"Wahrscheinlichkeit Klasse {i}: {probabilities[i]:.7f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7f8df0",
   "metadata": {},
   "source": [
    "## Hintergrundinformation: Weshalb Softmax im Modell-Training nicht verwendet wird\n",
    "\n",
    "Der Grund, warum die Softmax-Funktion im Modell-Training nicht direkt verwendet wird, liegt darin, dass die meisten Verlustfunktionen für Klassifikationsprobleme, wie z.B. die Kreuzentropie-Verlustfunktion, bereits die Softmax-Funktion intern anwenden. Somit müssen wir die Softmax-Funktion nicht explizit in unserem Modell verwenden, da sie bereits in der Verlustfunktion berücksichtigt wird."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "praktikum_ef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
