{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b9880fe",
   "metadata": {},
   "source": [
    "# pyTorch Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4453fb",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; border: 5px solid #a10000ff;\">\n",
    "\n",
    "**Hinweis:** In den Codezellen sind jeweils einige Codeteile nicht programmiert. Diesen Code müssen Sie ergänzen. Die jeweiligen Stellen sind mit einem Kommentar und dem Keyword **TODO** vermerkt und z.T. Stellen mit ... markiert.\n",
    "\n",
    "Ausserdem gibt es einige assert Statements. Diese geben einen Fehler aus, sollte etwas bei Ihrer Programmierung nicht korrekt sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa9d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055839ec",
   "metadata": {},
   "source": [
    "## Hintergrundinformationen zu CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de600c4",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks (CNNs) sind eine spezielle Art von künstlichen neuronalen Netzwerken, die besonders gut für die Verarbeitung von Bilddaten geeignet sind. Sie bestehen wie andere neuronale Netze aus mehreren Schichten, darunter Convolutional Layers, Pooling Layers und Fully Connected Layers.\n",
    "\n",
    "- **Convolutional Layers**: Diese Schichten verwenden Filter (auch als Kernel bezeichnet), um Features im Eingabebild zu erkennen. Dies ermöglicht es dem Netzwerk, Muster wie Kanten, Ecken und Texturen zu erkennen.\n",
    "- **Pooling Layers**: Diese Schichten reduzieren die räumlichen Dimensionen der Daten, indem sie Informationen zusammenfassen. Dies hilft, die Anzahl der Parameter zu reduzieren und die Rechenleistung zu verbessern.\n",
    "- **Fully Connected Layers**: Diese Schichten verbinden alle Neuronen der vorherigen Schicht mit allen Neuronen der nächsten Schicht. Sie werden oft am Ende eines CNNs verwendet, um die erkannten Features in eine Klassifikation oder Regression umzuwandeln.\n",
    "\n",
    "In diesem Notebook werden wir die Grundlagen von CNNs in PyTorch kennenlernen und ein erstes CNN für die Bildklassifikation implementieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e518e06",
   "metadata": {},
   "source": [
    "### Torch vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ca290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir prüfen ob eine Hardwarebeschleunigung möglich ist und verwenden diese, wenn sie verfügbar ist\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "torch.manual_seed(42) # Setze den Zufallsseed für Reproduzierbarkeit\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e1dac8",
   "metadata": {},
   "source": [
    "## MNIST Dataset vorbereiten, laden und visualisieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936bcff0",
   "metadata": {},
   "source": [
    "Wir nutzen für dieses Notebook den MNIST-Datensatz, der handgeschriebene Ziffern enthält. Die Ziffern sind in 10 Klassen (0-9) unterteilt, und jede Klasse enthält Tausende von Bildern. \n",
    "Die Bilder sind in Graustufen und haben eine Auflösung von 28x28 Pixeln.\n",
    "Das Modell muss lernen, diese Ziffern korrekt zu klassifizieren.\n",
    "\n",
    "Wir werden diesen Datensatz laden, vorbereiten und einige Beispiele visualisieren. Der Datensatz kann direkt von PyTorch heruntergeladen werden, was den Prozess vereinfacht.\n",
    "\n",
    "Quelle Dataset: [MNIST Dataset](https://pytorch.org/vision/stable/datasets.html#mnist)\n",
    "\n",
    "Originale nicht mehr existierende Webseite: [MNIST Dataset](http://yann.lecun.com/exdb/mnist/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f855ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mnist Dataset laden\n",
    "mnist_train = torchvision.datasets.MNIST(root='datasets', train=True, download=True)\n",
    "mnist_test = torchvision.datasets.MNIST(root='datasets', train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105edd58",
   "metadata": {},
   "source": [
    "### Machine Learning Prozess\n",
    "Der Machine Learning Prozess besteht aus mehreren Schritten, die nacheinander durchlaufen werden müssen, um ein funktionierendes Modell zu erstellen. Hier sind die Schritte im Überblick:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852df5d2",
   "metadata": {},
   "source": [
    "<img src=\"images/ml_process.png\" alt=\"Machine Learning Prozess\" width=\"600\"/>\n",
    "\n",
    "1. **Problemdefinition**: Das Problem, das gelöst werden soll, wird definiert. Es wird festgelegt, welche Art von Modell benötigt wird und welche Daten dafür erforderlich sind.\n",
    "\n",
    "2. **Daten sammeln& aufbereiten**: Die Daten, die für das Training des Modells benötigt werden, werden gesammelt. Dies kann durch Web-Scraping, APIs, Datenbanken oder andere Quellen erfolgen. Die gesammelten Daten werden bereinigt, transformiert und in ein Format gebracht, das für das Training des Modells geeignet ist. Dies kann das Entfernen von Duplikaten, das Auffüllen/Entfernen von fehlenden Werten oder die Normalisierung der Daten umfassen.\n",
    "\n",
    "3. **Modell erstellen**: Das Modell wird erstellt, indem die Architektur definiert und die Hyperparameter festgelegt werden. Dies kann die Auswahl von Schichten, Aktivierungsfunktionen, Optimierern und anderen Parametern umfassen.\n",
    "\n",
    "4. **Modell trainieren & evaluieren**: Das Modell wird mit den vorbereiteten Daten trainiert. Dies umfasst die Auswahl eines Trainingsalgorithmus, die Festlegung der Anzahl der Epochen und die Überwachung des Trainingsfortschritts. Das trainierte Modell wird bewertet, um seine Leistung zu messen. Dies kann die Berechnung von Metriken wie RMSE, Accuracy, Precision oder F1-Score umfassen.\n",
    "\n",
    "5. **Modell laufen lassen**: Das trainierte und evaluierte Modell wird in einer Produktionsumgebung eingesetzt, um Vorhersagen zu treffen oder Entscheidungen zu unterstützen.\n",
    "\n",
    "6. **Modell überwachen / ausser Betrieb nehmen**: Das Modell wird kontinuierlich überwacht, um sicherzustellen, dass es weiterhin gute Leistungen erbringt. Dies kann die Überwachung von Metriken, die Erkennung von Datenänderungen oder die Aktualisierung des Modells umfassen. Wenn das Modell nicht mehr benötigt wird oder nicht mehr gut funktioniert, kann es ausser Betrieb genommen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea9f364",
   "metadata": {},
   "source": [
    "### Daten validieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a5cfe",
   "metadata": {},
   "source": [
    "Wir prüfen die Daten auf Konsistenz, um sicherzustellen, dass die Daten für das Training eines Modells geeignet sind. In der Praxis wird ein Datensatz auf die Kriterien weiter unten geprüft. Da es ein vorbereiteter Datensatz ist, ist dieser bereits in einem guten Zustand und wir machen nur wenige **Konsistenz-Prüfungen**, um die Datenqualität zu validieren.\n",
    "\n",
    "**Datenqualitätskriterien:**\n",
    "- **Vollständigkeit**: Alle notwendigen Daten sind vorhanden, es gibt keine fehlenden Werte.\n",
    "- **Konsistenz**: Alle Daten sind im gleichen Format (z.B. gleiche Bildgrössen, gleiche Pixelwerte, keine Mischung von Datentypen z.B. Integer und Datum in selbem Feld)\n",
    "- **Richtigkeit**: Alle Daten sind korrekt und entsprechen der Realität (z.B. keine falschen Labels, keine fehlerhaften Werte)\n",
    "- **Einzigartigkeit**: Es gibt keine Duplikate in den Daten, die somit die Trainingsdaten verzerren könnten.\n",
    "- **Aktualität&Relevanz**: Alle Daten sind aktuell und relevant für das Problem, das gelöst werden soll."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81096280",
   "metadata": {},
   "source": [
    "Damit wir die Daten benutzen können, müssen alle Daten gleich formiert sein, heisst alle Bilder müssen die gleiche Grösse haben, die Pixelwerte müssen in einem bestimmten Bereich liegen, etc. \n",
    "In diesem Abschnitt prüfen wir, ob es verschiedene Bildgrössen gibt, ob alle Pixelwerte von 0 bis 255 reichen und zeigen ein Beispiel eines Bildes an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa778bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Anzahl Trainings- und Testdaten anzeigen\n",
    "print(f\"Anzahl Trainingsbilder: {len(mnist_train)}\")\n",
    "print(f\"Anzahl Testbilder: {len(mnist_test)}\")\n",
    "\n",
    "\n",
    "# Prüfen, dass alle Bilder die gleiche Grösse haben\n",
    "image_sizes = [image.size for image, _ in mnist_train]\n",
    "print(f\"Einzigartige Bildgrössen: {set(image_sizes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78296738",
   "metadata": {},
   "source": [
    "#### Prüfen der Pixelwerte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761b51c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prüfen, dass die Pixelwerte im Bereich von 0 bis 255 liegen\n",
    "pixel_values = [image.getdata() for image, _ in mnist_train]\n",
    "pixel_values_flat = [pixel for sublist in pixel_values for pixel in sublist]\n",
    "print(f\"Min Pixelwert: {min(pixel_values_flat)}\")\n",
    "print(f\"Max Pixelwert: {max(pixel_values_flat)}\")\n",
    "\n",
    "# Labels prüfen\n",
    "labels = [label for _, label in mnist_train]\n",
    "print(f\"Einzigartige Labels: {set(labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42f40ca",
   "metadata": {},
   "source": [
    "#### Beispiel Data Sample anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87858fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ein Beispielbild aus dem Trainingsdatensatz anzeigen\n",
    "image, label = mnist_train[0]\n",
    "print(f\"Label: {label}\")\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc1d563",
   "metadata": {},
   "source": [
    "#### Aufgabe 1\n",
    "\n",
    "1. Was bedeutet es, wenn die Bilder unterschiedliche Grössen haben? Was könnte das für Probleme verursachen?\n",
    "\n",
    "> \n",
    "\n",
    "2. Wenn wir das Modell auf neue Daten anwenden möchten, was müssen wir sicherstellen, damit das Modell die neuen Daten korrekt verarbeiten kann? Führen Sie dies anhand eines Bildes als Beispiel aus.\n",
    "\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea209be4",
   "metadata": {},
   "source": [
    "### Data Loader erstellen\n",
    "\n",
    "In diesem Abschnitt erstellen wir wieder einen Data Loader, um die Daten in Batches zu laden und für das Training vorzubereiten. \n",
    "Die Daten sind in Trainings- und Testset aufgeteilt.\n",
    "\n",
    "**Tensorkonvertierung & Normalisierung**: Es wird auch eine Transformation toTensor() von Torchvision angewendet. \n",
    "Diese Transformation konvertiert die Bilder in PyTorch-Tensoren, die für das Training des Modells erforderlich sind.\n",
    "Ausserdem normalisiert sie die Pixelwerte von 0-255 auf einen Bereich von 0-1, was die Stabilität des Trainings verbessert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42b2bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damit wir die Bilder in einem CNN verwenden können, müssen wir die Bilder in Tensoren umwandeln.\n",
    "\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "# Mit der Bibliothek Torchvision können wird das MNIST Dataset direkt herunterladen und in einem Schritt in Tensoren umwandeln. \n",
    "# Train=True lädt den Trainingsdatensatz, Train=False lädt den Testdatensatz.\n",
    "mnist_transformed_train = torchvision.datasets.MNIST(root='datasets', train=True, download=True, transform=transform)\n",
    "mnist_transformed_test = torchvision.datasets.MNIST(root='datasets', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(mnist_transformed_train, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(mnist_transformed_test, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b3bce1",
   "metadata": {},
   "source": [
    "## Neural Network Architektur definieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c99218",
   "metadata": {},
   "source": [
    "In diesem Abschnitt definieren wir die Architektur unseres Convolutional Neural Networks. \n",
    "\n",
    "Wir werden mehrere Convolutional Layers, Pooling Layers und Fully Connected Layers verwenden, um ein Modell zu erstellen, das in der Lage ist, die Bilder im MNIST-Datensatz zu klassifizieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3dca6",
   "metadata": {},
   "source": [
    "### Berechnung der Dimensionen der verschiedenen Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d877e6",
   "metadata": {},
   "source": [
    "In pyTorch müssen wir die Dimensionen der Daten durch die verschiedenen Schichten unseres Netzwerks verfolgen, um die Dimensionen der einzelnen Layers zu konfigurieren. In diesem Abschnitt berechnen wir die Dimensionen der Daten nach jeder Schicht in unserem CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139583f1",
   "metadata": {},
   "source": [
    "#### Aufgabe 2\n",
    "\n",
    "Wir möchten folgende Architektur für unser CNN verwenden:\n",
    "```\n",
    "Input (28x28) --> Conv1 (7x7, 12 Kernel, Stride 1, Padding 0) --> Pool1 (2x2, Stride 2) --> Conv2 (5x5, 16 Kernel, Stride 1, Padding 2) --> Pool2 (2x2, Stride 2) --> Fully Connected Layer\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1. Berechnen Sie die Bildgrösse nach dem ersten Convolutional Layer:\n",
    "Hinweis: Überlegen Sie sich wie sich die Bildgrösse mit dem verwendeten Kernel, Padding und Stride verändert.\n",
    "\n",
    ">\n",
    "\n",
    "2. Berechnen Sie die Bildgrösse nach dem ersten Pooling Layer:\n",
    "> \n",
    "\n",
    "3. Berechnen Sie die Bildgrösse nach dem zweiten Convolutional Layer:\n",
    "> \n",
    "\n",
    "4. Berechnen Sie die Bildgrösse nach dem zweiten Pooling Layer:\n",
    "> \n",
    "\n",
    "5. Wie viele Neuronen muss der Fully Connected Layer haben, um die Daten korrekt zu verarbeiten? (Tipp: wir müssen die Anzahl der Kanäle und die Bildgrösse nach dem letzten Pooling Layer berücksichtigen)\n",
    "\n",
    "> Nach dem zweiten Pooling haben wir 16 Kanäle und die Bildgrösse ist 5x5. Daher müssen wir 16 * 5 * 5 = 400 Neuronen im Fully Connected Layer haben, um alle Informationen aus den vorherigen Schichten zu verarbeiten.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c9134",
   "metadata": {},
   "source": [
    "### Aufgabe 3\n",
    "\n",
    "Programmieren Sie nun die Architektur des CNNs.\n",
    "\n",
    "**Convolutional Layer**: In PyTorch wird ein Convolutional Layer mit der Funktion `torch.nn.Conv2d` definiert. `torch` steht für PyTorch, `nn` für neural network und `Conv2d` für 2D Convolutional Layer.\n",
    "```python\n",
    "torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "```\n",
    "| Parameter | Erläuterung |\n",
    "|-----------|-------------|\n",
    "| `in_channels` | Anzahl der Eingabekanäle. |\n",
    "| `out_channels` |  Anzahl der Ausgabekanäle (Anzahl Kernels). |\n",
    "| `kernel_size` | Grösse des Kernels (7x7 Pixel). |\n",
    "| `stride` | Schrittweite beim Verschieben des Filters. Der Filter wird um 1 Pixel pro Schritt verschoben. |\n",
    "| `padding` |  Anzahl der Pixel, die um das Eingabebild herum hinzugefügt werden. Mit 0 wird die Bildgrösse reduziert. |\n",
    "\n",
    "\n",
    "Der **Pooling Layer** wird wie folgt definiert:\n",
    "```python\n",
    "torch.nn.MaxPool2d(kernel_size, stride),\n",
    "```\n",
    "\n",
    "| Parameter | Erläuterung |\n",
    "|-----------|-------------|\n",
    "| `kernel_size` | Grösse des Pooling-Fensters (2x2 Pixel). |\n",
    "| `stride` | Schrittweite beim Verschieben des \"Pooling-Fensters\". Der Filter wird um 2 Pixel pro Schritt verschoben. |\n",
    "\n",
    "Der **Fully Connected Layer** wird mit `nn.Linear` definiert:\n",
    "```python\n",
    "nn.Linear(in_features, out_features)\n",
    "```\n",
    "| Parameter | Erläuterung |\n",
    "|-----------|-------------|\n",
    "| `in_features` | Anzahl der Eingabefeatures (z.B. 400). |\n",
    "| `out_features` | Anzahl der Ausgabefeatures (z.B. 10 für die 10 Klassen). |\n",
    "\n",
    "\n",
    "Der **ReLU-Aktivierungsfunktion** wird mit `nn.ReLU()` definiert und fügt Nichtlinearität hinzu, damit das Netzwerk komplexe Muster lernen kann.\n",
    "\n",
    "Der **Flatten Layer** wird mit `nn.Flatten()` definiert und wandelt die mehrdimensionalen Daten in einen eindimensionalen Vektor um, der für den Fully Connected Layer geeignet ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48608e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO erstellen Sie mit torch.nn.sequential ein Convolutional Neural Network mit folgenden Schichten. Die Schichten werden als einzelne Parameter an torch.nn.Sequential übergeben.\n",
    "# - Convolutional Layer mit einem Eingabe-Kanal, 12 Ausgabekanälen, einem Kernel von 7x7, einem Stride von 1 und einem Padding von 0\n",
    "# - Max Pooling Layer mit einem Kernel von 2x2 und einem Stride von 2\n",
    "# - RELU Aktivierungsfunktion\n",
    "# - Convolutional Layer mit 12 Eingabekanälen, 16 Ausgabekanälen, einem Kernel von 5x5, einem Stride von 1 und einem Padding von 2\n",
    "# - Max Pooling Layer mit einem Kernel von 2x2 und einem Stride von 2\n",
    "# - RELU Aktivierungsfunktion\n",
    "# - Flatten Layer, um die Daten für die Fully Connected Layer vorzubereiten\n",
    "# - Fully Connected Layer mit der Anzahl Eingabeneuronen die Sie oben berechnet haben und 10 Ausgabeneuronen.\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a72bc85",
   "metadata": {},
   "source": [
    "## Netzwerk trainieren und evaluieren\n",
    "In diesem Abschnitt trainieren wir unser CNN mit dem MNIST-Datensatz und evaluieren die Leistung des Modells auf dem Testset. Wir werden die Trainings- und Testgenauigkeit berechnen und die Ergebnisse visualisieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3164ac6",
   "metadata": {},
   "source": [
    "### Netzwerk trainieren\n",
    "\n",
    "Vervollständigen Sie den Trainingsloop, um das CNN zu trainieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304baf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter definieren\n",
    "max_num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "\n",
    "# Optimizer und die Loss-Funktion definieren\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Das Modell muss noch auf die Hardware verschoben werden.\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(max_num_epochs):\n",
    "    batch_train_losses = []\n",
    "    batch_test_losses = []\n",
    "    for batch in train_loader:\n",
    "        images, labels = batch\n",
    "\n",
    "        # Wir verschieben die Bilder und Labels auf die gleiche Hardware wie das Modell (CPU oder GPU)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        train_loss = loss(outputs, labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_train_losses.append(train_loss.item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            images, labels = batch\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            batch_test_losses.append(loss(outputs, labels).item())\n",
    "\n",
    "    training_loss = np.mean(batch_train_losses)\n",
    "    testing_loss = np.mean(batch_test_losses)\n",
    "    train_losses.append(training_loss)\n",
    "    test_losses.append(testing_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch}: Train Loss = {training_loss:.5f}, Test Loss = {testing_loss:.5f}\")\n",
    "\n",
    "# Modell speichern\n",
    "torch.save(model.state_dict(), 'mnist_cnn.pth')\n",
    "\n",
    "\n",
    "# Test und Trainingsverluste visualisieren\n",
    "plt.plot(train_losses, label='Trainings Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epochen')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Trainings- und Testverlust über Epochen')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbeb7f5",
   "metadata": {},
   "source": [
    "### Modell Laden und Testen\n",
    "Nachdem wir das Modell trainiert und gespeichert haben, können wir es laden und auf neuen Daten testen. In diesem Abschnitt laden wir das gespeicherte Modell und evaluieren es auf dem Testset, um die Genauigkeit zu berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testen ob das File für das Modell existiert und das Modell geladen werden kann\n",
    "if os.path.exists(\"mnist_cnn.pth\"):\n",
    "    model.load_state_dict(torch.load(\"mnist_cnn.pth\"))\n",
    "    print(\"Modell erfolgreich geladen!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065b653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne die Accuracy des Modells auf dem Testset\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        images, labels = batch\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfaf0ad",
   "metadata": {},
   "source": [
    "#### Aufgabe 4\n",
    "\n",
    "Was bedeutet die Accuracy Metrik? Wie gut funktioniert unser Modell?\n",
    "\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9687ce",
   "metadata": {},
   "source": [
    "## Kontrollfragen\n",
    "\n",
    "1. Wie ist die Architektur eines Convolutional Neural Networks aufgebaut? Welche Schichten werden verwendet und welche Funktionen haben sie?\n",
    "\n",
    "> \n",
    "\n",
    "2. Was ist der Unterschied zwischen einem Convolutional Layer und einem Fully Connected Layer?\n",
    "\n",
    "> \n",
    "3. Wie berechnet man die Eingangsdimensionen des Fully-Connected Layers am Ende des CNNs?\n",
    "\n",
    "> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "praktikum_ef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
