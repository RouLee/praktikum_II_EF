{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b9880fe",
   "metadata": {},
   "source": [
    "# Training, Learning, Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2954ec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas matplotlib seaborn scikit-learn torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda0f5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc8de58",
   "metadata": {},
   "source": [
    "## Datenset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ca369e",
   "metadata": {},
   "source": [
    "Wir möchten in dieser Übung mit dem Datenset der Titanic Passagiere arbeiten. Dabei sind in den Daten folgende Merkmale (Features) festgehalten.\n",
    "\n",
    "- **Survived**: 1= Hat überlebt, 0= hat nicht überlebt\n",
    "- **Sex**: 1 = weiblich, 0 = männlich\n",
    "- **Age**: Alter der Personen\n",
    "- **Pclass**: In welcher Klasse die Person gereist ist.\n",
    "\n",
    "Wir möchten mit unserem Modell vorhersagen ob eine Person aufgrund der Merkmale Sex, Age, Pclass überlebt hat oder nicht. Wir sagen somit das Target \"Survived\" mit den Features \"Sex\", \"Age\" und \"Pclass\" voraus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d507cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir laden das Datenset mit den Angaben zu den Titanic Passagieren\n",
    "data_training = pd.read_csv('./datasets/titanic_train.csv')\n",
    "data_test = pd.read_csv('./datasets/titanic_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f3940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainings und Testdaten vorbereiten\n",
    "\n",
    "X_test = data_test[['Pclass', 'Age', 'Sex']]\n",
    "y_test = data_test['Survived']\n",
    "\n",
    "X_train = data_training[['Pclass', 'Age', 'Sex']]\n",
    "y_train = data_training['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39006b7",
   "metadata": {},
   "source": [
    "## Modell erstellen und trainieren\n",
    "\n",
    "Beantworten Sie die Fragen unterhalb des Codeblocks. Der Code soll nicht verändert werden. Die Kommentare sollen ergänzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda7e611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir nutzen nun ein Modell um das Überleben der Passagiere vorherzusagen\n",
    "\n",
    "# Wir erstellen ein erstes einfaches Modell mti PyTorch\n",
    "# Die Details müssen Sie noch nicht verstehen\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 2),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "# Für pytorch müssen wir die Daten in Tensors umwandeln\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Wir definieren die Loss-Funktion und den Optimizer. Der Optimizer aktualisiert die Gewichte des Modells basierend auf dem berechneten Loss.\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# ...\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # ...\n",
    "    y_pred = model(X_train_tensor)\n",
    "\n",
    "    # ...\n",
    "    loss = loss_fn(y_pred, y_train_tensor)\n",
    "\n",
    "    # Wir setzen die Gradienten auf Null zurück. \n",
    "    # Dies ist notwendig, da PyTorch die Gradienten standardmässig aufsummiert und wir aus der letzten Epocheen nicht beeinflusst werden möchten.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # ...\n",
    "    loss.backward()\n",
    "\n",
    "    # ...\n",
    "    optimizer.step()\n",
    "\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_test_pred = model(X_test_tensor)\n",
    "        test_loss = loss_fn(y_test_pred, y_test_tensor)\n",
    "        test_losses.append(test_loss.item())\n",
    "\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962fdb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wir zeigen nun den Loss nach jeder Epoche an\n",
    "plt.plot(range(num_epochs), train_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add93fda",
   "metadata": {},
   "source": [
    "## Aufgabe 1\n",
    "**Frage A** Was sind im Code die Epochen? Halten Sie dies als Code-Kommentar fest.\n",
    "\n",
    "**Frage B** Nach wie vielen Epochen haben wir fast keine Verbesserung mehr im Loss?\n",
    "\n",
    "**Frage C** Wo im Code werden die Vorhersagen des Modells mit den echten Targets verglichen? Halten Sie dies als Kommentar fest.\n",
    "\n",
    "**Frage D** Wo im Code lernt das Modell aus den Fehlern? Halten Sie dies im Code als Kommentar fest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fc0d2d",
   "metadata": {},
   "source": [
    "## Modell Testen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e0754d",
   "metadata": {},
   "source": [
    "Wir haben gesehen, dass sich das Modell bereits nach einigen Epochen nicht mehr viel verbessert. \n",
    "\n",
    "Bis anhin haben wir nur auf den Trainingsdaten gelernt und da den Fehler ausgewertet. Was wir nun aber machen wollen ist, zu schauen wie gut das Modell mit ungesehenen Daten umgehen kann.\n",
    "Dazu plotten wir nun auch den Loss auf den Testdaten.\n",
    "\n",
    "Mit der Anweisung `with torch.no_grad():` stellen wir sicher, dass das Modell nicht aus den Testdaten lernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab7ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wir zeigen nun den Loss nach jeder Epoche an\n",
    "plt.plot(range(num_epochs), train_losses, label='Train Loss')\n",
    "plt.plot(range(num_epochs), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee929abf",
   "metadata": {},
   "source": [
    "## Aufgabe 2\n",
    "\n",
    "**Frage A**: Was beobachten Sie bezüglich dem Train und dem Test Loss?\n",
    "\n",
    "**Frage B**: Was ist der Zweck, dass Testdaten eingesetzt werden und weshalb möchten wir, dass das Modell aus diesen Daten nicht lernt?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0468704c",
   "metadata": {},
   "source": [
    "## Aufgabe 3\n",
    "\n",
    "Unten wurde für ein Netzwerk der Loss im Bezug zum Modellparameter w symbolisch aufgezeichnet.\n",
    "\n",
    "\n",
    "**Frage A:** Welche Lösungsmöglichkeiten sehen Sie, dass wir nicht in einem lokalen Minimum hängen bleiben?\n",
    "\n",
    "**Frage B:** Welchen Einfluss hat die Initialisierung der Modellparameter bzw. Gewichte auf das Ergebnis der Optimierung des Modells?\n",
    "\n",
    "**Frage C:** Wo im Code von Aufgabe 1 findet die Gradientenberechnung und die Backward Propagation statt? Halten Sie dies als Kommentar im Code fest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d249fec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir plotten eine Loss Funktion, welche mehrere lokale Minima hat\n",
    "def complex_loss(x):\n",
    "    return np.sin(3 * x) + 0.5 * np.cos(5 * x) + 0.2 * x\n",
    "x = np.linspace(-5, 5, 400)\n",
    "y = complex_loss(x)\n",
    "plt.plot(x, y)\n",
    "plt.title('Loss Function')\n",
    "plt.xlabel('w')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "praktikum_ef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
