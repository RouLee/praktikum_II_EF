{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b9880fe",
   "metadata": {},
   "source": [
    "# pyTorch Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4453fb",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; border: 5px solid #a10000ff;\">\n",
    "\n",
    "**Hinweis:** In den Codezellen sind jeweils einige Codeteile nicht programmiert. Diesen Code müssen Sie ergänzen. Die jeweiligen Stellen sind mit einem Kommentar und dem Keyword **TODO** vermerkt und z.T. Stellen mit ... markiert.\n",
    "\n",
    "Ausserdem gibt es einige assert Statements. Diese geben einen Fehler aus, sollte etwas bei Ihrer Programmierung nicht korrekt sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa9d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055839ec",
   "metadata": {},
   "source": [
    "## Hintergrundinformationen zu Tensoren und Gradienten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d78f11",
   "metadata": {},
   "source": [
    "Wenn dies auf Ihrem System verfügbar ist, kann PyTorch auch die Grafikkarte (GPU) nutzen um die Berechnungen zu beschleunigen. Ausserdem setzen wir den Random-Number Seed so, dass immer die gleichen Zahlen resultieren. Dies hilft dabei um eine Reproduzierbarkeit zu erreichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fea290",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "torch.manual_seed(42) # Setze den Zufallsseed für Reproduzierbarkeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dd7641",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af15b7df",
   "metadata": {},
   "source": [
    "Tensoren sind das PyTorch-Äquivalent zu Numpy-Arrays, mit dem zusätzlichen Vorteil der GPU-Beschleunigung (Grafikkarte).\n",
    "Der Name \"Tensor\" ist eine Verallgemeinerung von Konzepten, die Sie bereits kennen. Zum Beispiel ist ein Vektor ein 1-D Tensor und eine Matrix ein 2-D Tensor. Wir werden Tensoren mit verschiedenen Dimensionen verwenden.\n",
    "\n",
    "Die meisten gängigen Funktionen, die Sie aus Numpy kennen, können auch auf Tensoren angewendet werden. Da Numpy-Arrays und Tensoren sich sehr ähneln, können wir die meisten Tensoren in Numpy-Arrays konvertieren (und umgekehrt), müssen das aber nicht oft tun.\n",
    "\n",
    "Der folgende Tensor hat zum Beispiel drei Dimensionen und eine Grösse von 2x3x4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd02454",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(2, 3, 4)\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162a7d67",
   "metadata": {},
   "source": [
    "\n",
    "Tensoren können in Numpy-Arrays konvertiert werden, und Numpy-Arrays zurück in Tensoren. Um ein Numpy-Array in einen Tensor umzuwandeln, können wir die Funktion `torch.from_numpy` verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74c5b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_arr = np.array([[1, 2], [3, 4]])\n",
    "tensor = torch.from_numpy(np_arr)\n",
    "\n",
    "print(\"Numpy array:\", np_arr)\n",
    "print(\"PyTorch tensor:\", tensor)\n",
    "\n",
    "np_arr = tensor.numpy()\n",
    "\n",
    "print(\"PyTorch tensor:\", tensor)\n",
    "print(\"Numpy array:\", np_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2fc67d",
   "metadata": {},
   "source": [
    "**Wichtig:** Die Konvertierung von Tensoren zu Numpy erfordert, dass der Tensor auf der CPU und nicht auf der GPU ist. Falls Sie einen Tensor auf der GPU haben, müssen Sie zuerst `.cpu()` auf dem Tensor aufrufen. Daher erhalten Sie eine Zeile wie `np_arr = tensor.cpu().numpy()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8918986",
   "metadata": {},
   "source": [
    "### Automatische Ableitung (Gradient Berechnung)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef16e00",
   "metadata": {},
   "source": [
    "Einer der Hauptgründe für die Verwendung von PyTorch in Deep-Learning-Projekten ist, dass wir automatisch **Gradienten/Ableitungen** von Funktionen erhalten können, die wir definieren. Wir werden PyTorch hauptsächlich zur Implementierung neuronaler Netze verwenden. Wenn wir in unseren Neuronalen Netzwerken Parameter haben, die wir lernen möchten, werden diese als **Parameter** oder einfach als **Gewichte** bezeichnet. Diese können von Pytorch automatisch gelernt werden indem die Ableitung berechnet wird.\n",
    "\n",
    "Manchmal wollen wir aber nicht, dass der Gradient berechnet wird, beziehungsweise dies deaktivieren. Wenn wir zum Beispiel ein Netzwerk evaluieren können wir somit sicherstellen, dass keien Gradienten berechnet werden. Dies können wir mit `with torch.no_grad()` für einen gesamten Codeblock tun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b84c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y = x + 2\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dae59a3",
   "metadata": {},
   "source": [
    "### Optional: Hintergrundinfos zum Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6436cc37",
   "metadata": {},
   "source": [
    "Die Klasse `torch.utils.data.DataLoader` stellt einen Python-Iterator über einen Datensatz dar und bietet z.B. automatisches Batching. Der Data Loader kommuniziert mit dem Datensatz über die Funktion `__getitem__` und stapelt ihre Ausgaben als Tensoren über die erste Dimension zu einem Batch.\n",
    "\n",
    "Im Gegensatz zur Dataset-Klasse müssen wir normalerweise keine eigene Data-Loader-Klasse definieren, sondern können einfach ein Objekt davon mit dem Datensatz als Eingabe erstellen. Zusätzlich können wir unseren Data Loader mit den folgenden Eingabeargumenten konfigurieren (nur eine Auswahl, vollständige Liste [hier](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)):\n",
    "\n",
    "* `batch_size`: Anzahl der Samples pro Batch\n",
    "* `shuffle`: Falls True, werden die Daten in zufälliger Reihenfolge zurückgegeben. Dies ist wichtig während des Trainings zur Einführung von Stochastizität.\n",
    "* `num_workers`: Anzahl der Subprozesse für das Datenladen. Der Standard 0 bedeutet, dass Daten im Hauptprozess geladen werden, was das Training bei Datensätzen mit langen Ladezeiten verlangsamen kann (z.B. grosse Bilder). Mehr Worker werden empfohlen, können aber auf Windows-Computern Probleme verursachen. Bei kleinen Datensätzen wie unserem ist 0 Worker normalerweise schneller.\n",
    "* `drop_last`: Falls True, wird der letzte Batch verworfen, falls er kleiner als die spezifizierte Batch-Grösse ist. Dies tritt auf, wenn die Datensatzgrösse nicht ein Vielfaches der Batch-Grösse ist. Nur möglicherweise hilfreich während des Trainings zur Konsistenz der Batch-Grösse.\n",
    "\n",
    "Unten erstellen wir einen einfachen Data Loader mit einem gegebenen Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd8e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir erstellen einen Regressionsdatensatz aus sklearn in einen DataLoader von pytorch\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "dataloader = DataLoader(torch.utils.data.TensorDataset(torch.tensor(X, dtype=torch.float32),\n",
    "                                                        torch.tensor(y, dtype=torch.float32)), batch_size=10)\n",
    "\n",
    "for batch_X, batch_y in dataloader:\n",
    "    print(batch_X.shape, batch_y.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71de3f1c",
   "metadata": {},
   "source": [
    "## Aufgaben Beispiel Netzwerk trainieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f40fe6",
   "metadata": {},
   "source": [
    "Wir betrachten ein Dataset, welches 11 Eigenschaften von Weinen enthält. Es ist nun die Aufgabe eines Machine Learning Modells die Weinqualität vorherzusagen. In diesem Notebook werden wir ein einfaches neuronales Netzwerk mit einer versteckten Schicht implementieren und trainieren. Das Ziel ist es, die Grundlagen von PyTorch zu verstehen, einschließlich der Erstellung von Modellen, der Definition von Lossfunktionen und der Durchführung von Trainingsschritten.\n",
    "\n",
    "Das Dataset hat folgende Features (Merkmale der Weine):\n",
    "1. **fixed acidity**: Die Menge an festen Säuren im Wein, gemessen in Gramm pro Liter.\n",
    "2. **volatile acidity**: Die Menge an flüchtigen Säuren im Wein, gemessen in Gramm pro Liter. \n",
    "3. **citric acid**: Die Menge an Zitronensäure im Wein, gemessen in Gramm pro Liter.\n",
    "4. **residual sugar**: Die Menge an Restzucker im Wein, gemessen in Gramm pro Liter. \n",
    "5. **chlorides**: Die Menge an Chloriden im Wein, gemessen in Gramm pro Liter\n",
    "6. **free sulfur dioxide**: Die Menge an freiem Schwefeldioxid im Wein, gemessen in Milligramm pro Liter\n",
    "7. **total sulfur dioxide**: Die Gesamtmenge an Schwefeldioxid im Wein, gemessen in Milligramm pro Liter. \n",
    "8. **density**: Die Dichte des Weins, gemessen in Gramm pro Kubikzentimeter.\n",
    "9. **pH**: Der pH-Wert des Weins.\n",
    "10. **sulphates**: Die Menge an Sulfaten im Wein, gemessen in Gramm pro Liter.\n",
    "11. **alcohol**: Der Alkoholgehalt des Weins, gemessen in Volumenprozent.\n",
    "\n",
    "Quality ist die Zielvariable (Target), die die Qualität des Weins auf einer Skala von 0 bis 10 bewertet. In diesem Notebook werden wir versuchen, diese Qualität basierend auf den 11 Eigenschaften vorherzusagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761ab181",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_dataframe = pd.read_csv(\"datasets/wineQT.csv\", index_col=\"Id\")\n",
    "wine_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a91ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir splitten die Daten in Trainings- und Testdaten\n",
    "train_df, test_df = train_test_split(wine_dataframe, test_size=0.2, random_state=42)\n",
    "print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfe07aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir erstellen einen DataLoader für die Trainingsdaten\n",
    "# Der hilft uns, dass wir die Daten in Batches also in Stücken durch das Netzwerk passieren können ohne alles auf einmal laden zu müssen\n",
    "# Dies macht das Training effizienter und spart Speicherplatz\n",
    "\n",
    "train_loader = DataLoader(torch.utils.data.TensorDataset(\n",
    "    torch.tensor(train_df.drop(\"quality\", axis=1).values, dtype=torch.float32),\n",
    "    torch.tensor(train_df[\"quality\"].values, dtype=torch.float32)\n",
    "), batch_size=16, shuffle=True, drop_last=True)\n",
    "\n",
    "for batch_X, batch_y in train_loader:\n",
    "    print(batch_X.shape, batch_y.shape)\n",
    "    break\n",
    "\n",
    "# Wir erstellen einen DataLoader für die Testdaten\n",
    "test_loader = DataLoader(torch.utils.data.TensorDataset(\n",
    "    torch.tensor(test_df.drop(\"quality\", axis=1).values, dtype=torch.float32),\n",
    "    torch.tensor(test_df[\"quality\"].values, dtype=torch.float32)\n",
    "), batch_size=16, shuffle=False, drop_last=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2ac2c5",
   "metadata": {},
   "source": [
    "### Aufgabe 1 Traingsloop implementieren\n",
    "\n",
    "In der folgenden Zelle soll eine Funktion erstellt werden womit ein Trainingsloop implementiert werden. Dieser soll für eine gegebene Anzahl Epochen über die Trainingsdaten iterieren, die Vorhersagen des Modells berechnen, den Verlust (MSELoss) bestimmen, den Gradienten berechnen und die Modellparameter mit dem Adam-Optimizer updaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8158190d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # TODO Vervollständigen Sie die Funktion train_model unten\n",
    "def train_model(model, train_loader, loss_function, optimizer, num_epochs):\n",
    "    trainlosses = []\n",
    "    # testlosses = [] # Kann optional verwendet werden, um den Testloss zu verfolgen\n",
    "    for epoch in range(num_epochs):\n",
    "        batch_losses = []\n",
    "        for batch_inputs, batch_targets in train_loader:\n",
    "            # Vorhersagen berechnen\n",
    "            predictions = model(batch_inputs)\n",
    "            \n",
    "            # Verlust berechnen\n",
    "            loss = loss_function(predictions.squeeze(), batch_targets)\n",
    "            \n",
    "            # Gradienten zurücksetzen\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Gradienten berechnen\n",
    "            loss.backward()\n",
    "            \n",
    "            # Modellparameter updaten\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch_losses.append(loss.item())\n",
    "        # testlosses.append(test_model(model, test_loader, loss_function)) # Kann optional verwendet werden, um den Testloss zu verfolgen\n",
    "        \n",
    "        trainlosses.append(np.mean(batch_losses))\n",
    "\n",
    "    return trainlosses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b518939",
   "metadata": {},
   "source": [
    "### Aufgabe 2: Model testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdf51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Schreiben Sie eine Funktion test_model, die das Modell evaluiert. \n",
    "# Diese macht ähnliche Schritte wie die train_model Funktion, aber ohne Gradientenberechnung und Parameter-Updates.\n",
    "# Wir können dazu mit torch.no_grad(): den Gradientenmodus ausschalten und Speicher sparen.\n",
    "\n",
    "def test_model(model, test_loader, loss_function):\n",
    "    with torch.no_grad():\n",
    "        test_losses = []\n",
    "        for batch_inputs, batch_targets in test_loader:\n",
    "            # Vorhersagen berechnen\n",
    "            predictions = model(batch_inputs)\n",
    "            \n",
    "            # Verlust berechnen\n",
    "            loss = loss_function(predictions.squeeze(), batch_targets)\n",
    "            test_losses.append(loss.item())\n",
    "        \n",
    "        average_loss = sum(test_losses) / len(test_losses)\n",
    "        #print(f\"Average test loss: {average_loss}\")\n",
    "        return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad096c2b",
   "metadata": {},
   "source": [
    "### Aufgabe 3: Model erstellen und trainieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571da5ba",
   "metadata": {},
   "source": [
    "Erstellen Sie ein Model mit einer versteckten Schicht mit 50 Neuronen und ReLU Aktivierungsfunktion. Trainieren Sie das Model anschliessend mit dem Trainingsloop aus Aufgabe 1 für 100 Epochen. Verwenden Sie eine Lernrate von 0.001 und eine Batch-Grösse von 32. Geben Sie danach den finalen Trainingsloss aus.\n",
    "\n",
    "Das Dataset hat 11 Input-Features und 1 Target (Weinqualität). Deshalb benötigt das Model 11 Input-Neuronen und 1 Output-Neuron. Das Model soll direkt den Weinqualität-Wert vorhersagen (Regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68864fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Modell erstellen mit einer versteckten Schicht mit 50 Neuronen und ReLU Aktivierungsfunktion\n",
    "# Verwenden Sie wie im ersten Beispiel nn.Sequential mit Linear Layers und einer ReLU Aktivierungsfunktion dazwischen\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(11, 50),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 1)\n",
    ")\n",
    "# Modell auf das richtige Gerät verschieben (CPU oder GPU)\n",
    "model.to(device)\n",
    "\n",
    "# TODO Verlustfunktion und Optimizer definieren\n",
    "loss_function = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# TODO Trainieren Sie das Model mit dem Trainingsloop aus Aufgabe 1 für 100 Epochen\n",
    "num_epochs = 100\n",
    "train_losses = train_model(model, train_loader, loss_function, optimizer, num_epochs)\n",
    "print(f\"Final training loss: {train_losses[-1]}\")\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05fedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_test_loss = test_model(model, test_loader, loss_function)\n",
    "print(f\"Final test loss: {average_test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51b65ec",
   "metadata": {},
   "source": [
    "### Aufgabe 4: Modell speichern und laden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ef9da4",
   "metadata": {},
   "source": [
    "Sie haben beobachtete, dass das Training des Modells einige Sekunden dauert. Bei grösseren Modellen und Datensätzen kann das Training Minuten oder Stunden dauern. Um das trainierte Modell später wiederverwenden zu können, ohne es erneut trainieren zu müssen, können wir die Modellparameter speichern und später wieder laden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa264a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO speichern und laden Sie das trainierte Modell mit torch.save und torch.load\n",
    "\n",
    "#Speichern des Modells\n",
    "torch.save(model.state_dict(), \"trained_model.pth\")\n",
    "# Es werden nur die Modellparameter gespeichert, nicht die gesamte Modellarchitektur. \n",
    "# Deshalb müssen wird das Modell erneut definieren bevor wir die Parameter laden können.\n",
    "\n",
    "loaded_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(11, 50),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 1)\n",
    ")\n",
    "loaded_model.load_state_dict(torch.load(\"trained_model.pth\"))\n",
    "loaded_model.to(device)\n",
    "\n",
    "# Wir testen das Modell nochmals nach dem Laden\n",
    "loaded_model.eval()\n",
    "average_test_loss_loaded = test_model(loaded_model, test_loader, loss_function)\n",
    "\n",
    "## Erscheint der gleiche Testloss wie in Aufgabe 3?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e71626",
   "metadata": {},
   "source": [
    "### Aufgabe 5: Optional: Modell-Trainingsverlauf visualisieren\n",
    "\n",
    "Plotten Sie den Trainingsverlust über die Epochen um den Trainingsverlauf zu visualisieren.\n",
    "\n",
    "**Frage:** Hat es Sinn gemacht, das Modell über 100 Epochen zu trainieren? Oder hätte es auch mit weniger Epochen gereicht?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(1, num_epochs + 1), train_losses, label=\"Trainingsloss\")\n",
    "ax.set_xlabel(\"Epoche\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"Trainingsverlauf\")\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0820d669",
   "metadata": {},
   "source": [
    "### Aufgabe 6: Optional: Modell ändern\n",
    "\n",
    "In der vorherigen Aufgabe haben Sie ein einfaches Feedforward-Netzwerk mit einer versteckten Schicht implementiert. Versuchen Sie nun, die Modellarchitektur zu ändern. Sie können z.B. weitere versteckte Schichten hinzufügen, die Anzahl der Neuronen pro Schicht ändern oder andere Aktivierungsfunktionen ausprobieren. Trainieren Sie das verbesserte Modell erneut und vergleichen Sie die Testergebnisse mit dem ursprünglichen Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88060eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Verbessertes Modell erstellen und testen\n",
    "improved_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(11, 50),\n",
    "    torch.nn.LogSigmoid(),\n",
    "    torch.nn.Linear(50, 50),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(50, 1)\n",
    ")\n",
    "improved_model.to(device)\n",
    "improved_optimizer = torch.optim.Adam(improved_model.parameters(), lr=0.001)\n",
    "improved_train_losses = train_model(improved_model, train_loader, loss_function, improved_optimizer, num_epochs)\n",
    "average_test_loss_improved = test_model(improved_model, test_loader, loss_function)\n",
    "print(f\"Final training loss of improved model: {improved_train_losses[-1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "praktikum_ef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
